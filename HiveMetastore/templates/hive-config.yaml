apiVersion: v1
kind: ConfigMap
metadata:
  name: "{{ .Release.Name}}-hive-config"
{{- if .Values.s3.enabled}}
{{- if .Values.s3.internal}}
data: 
  core-site.xml: |
    <configuration>
      <property>
        <name>fs.defaultFS</name>
        <value>s3a://{{ .Release.Name}}-minio:9000</value>
      </property>
      <!-- Minio properties -->
      <property>
         <name>fs.s3a.connection.ssl.enabled</name>
         <value>{{ .Values.s3.coreSite.connectionSslEnabled | default false}}</value>
      </property>
      <property>
         <name>fs.s3a.endpoint</name>
         <value>http://{{ .Release.Name}}-minio:9000</value>
      </property>
      <property>
         <name>fs.s3a.access.key</name>
         <value>{{ .Values.s3.rootUser}}</value>
      </property>
      <property>
         <name>fs.s3a.secret.key</name>
         <value>{{ .Values.s3.rootPassword}}</value>
      </property>
      <property>
         <name>fs.s3a.path.style.access</name>
         <value>{{ .Values.s3.coreSite.pathStyleAccess | default true}}</value>
      </property>
      <property>
         <name>fs.s3a.impl</name>
         <value>org.apache.hadoop.fs.s3a.S3AFileSystem</value>
      </property>
    </configuration>
  metastore-site.xml: |
    <configuration>
      <property>
        <name>metastore.task.threads.always</name>
        <value>org.apache.hadoop.hive.metastore.events.EventCleanerTask,org.apache.hadoop.hive.metastore.MaterializationsCacheCleanerTask</value>
      </property>
      <property>
        <name>metastore.expression.proxy</name>
        <value>org.apache.hadoop.hive.metastore.DefaultPartitionExpressionProxy</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.postgresql.Driver</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:postgresql://{{ .Release.Name }}-pg-metastore-svc:5432/metadata</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>password</value>
      </property>
      <property>
        <name>hive.metastore.uris</name>
        <value>thrift://localhost:9083</value>
      </property>
      <property>
        <name>metastore.thrift.port</name>
        <value>9083</value>
      </property>
    </configuration>
  metastore-log4j2.properties: |
    # Licensed to the Apache Software Foundation (ASF) under one
    # or more contributor license agreements.  See the NOTICE file
    # distributed with this work for additional information
    # regarding copyright ownership.  The ASF licenses this file
    # to you under the Apache License, Version 2.0 (the
    # "License"); you may not use this file except in compliance
    # with the License.  You may obtain a copy of the License at
    #
    #     http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.

    status = INFO
    name = MetastoreLog4j2
    packages = org.apache.hadoop.hive.metastore

    # list of properties
    property.metastore.log.level = INFO
    property.metastore.root.logger = DRFA
    property.metastore.log.dir = ${sys:java.io.tmpdir}/${sys:user.name}
    property.metastore.log.file = metastore.log
    property.hive.perflogger.log.level = INFO

    # list of all appenders
    appenders = console, DRFA

    # console appender
    appender.console.type = Console
    appender.console.name = console
    appender.console.target = SYSTEM_ERR
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{ISO8601} %5p [%t] %c{2}: %m%n

    # daily rolling file appender
    appender.DRFA.type = RollingRandomAccessFile
    appender.DRFA.name = DRFA
    appender.DRFA.fileName = ${sys:metastore.log.dir}/${sys:metastore.log.file}
    # Use %pid in the filePattern to append <process-id>@<host-name> to the filename if you want separate log files for different CLI session
    appender.DRFA.filePattern = ${sys:metastore.log.dir}/${sys:metastore.log.file}.%d{yyyy-MM-dd}
    appender.DRFA.layout.type = PatternLayout
    appender.DRFA.layout.pattern = %d{ISO8601} %5p [%t] %c{2}: %m%n
    appender.DRFA.policies.type = Policies
    appender.DRFA.policies.time.type = TimeBasedTriggeringPolicy
    appender.DRFA.policies.time.interval = 1
    appender.DRFA.policies.time.modulate = true
    appender.DRFA.strategy.type = DefaultRolloverStrategy
    appender.DRFA.strategy.max = 30

    # list of all loggers
    loggers = DataNucleus, Datastore, JPOX, PerfLogger

    logger.DataNucleus.name = DataNucleus
    logger.DataNucleus.level = ERROR

    logger.Datastore.name = Datastore
    logger.Datastore.level = ERROR

    logger.JPOX.name = JPOX
    logger.JPOX.level = ERROR

    logger.PerfLogger.name = org.apache.hadoop.hive.ql.log.PerfLogger
    logger.PerfLogger.level = ${sys:hive.perflogger.log.level}

    # root logger
    rootLogger.level = ${sys:metastore.log.level}
    rootLogger.appenderRefs = root
    rootLogger.appenderRef.root.ref = ${sys:metastore.root.logger}
  
{{- else}}
data:
  core-site.xml: |
        <configuration>
            <property>
                <name>fs.defaultFS</name>
                <value>{{ .Values.s3.coreSite.defaultFS}}</value>
            </property>
            <!-- Minio properties -->
            <property>
                <name>fs.s3a.connection.ssl.enabled</name>
                <value>{{ .Values.s3.coreSite.connectionSslEnabled | default false}}</value>
            </property>
            <property>
                <name>fs.s3a.endpoint</name>
                <value>{{ .Values.s3.coreSite.endpoint}}</value>
            </property>
            <property>
                <name>fs.s3a.access.key</name>
                <value>{{ .Values.minio.rootUser}}</value>
            </property>

            <property>
                <name>fs.s3a.secret.key</name>
                <value>{{ .Values.minio.rootPassword}}</value>
            </property>
            <property>
                <name>fs.s3a.path.style.access</name>
                <value>{{ .Values.s3.coreSite.pathStyleAccess | default true}}</value>
            </property>
            <property>
                <name>fs.s3a.impl</name>
                <value>org.apache.hadoop.fs.s3a.S3AFileSystem</value>
            </property>
        </configuration>
  
  metastore-site.xml: |
    <configuration>
      <property>
        <name>metastore.task.threads.always</name>
        <value>org.apache.hadoop.hive.metastore.events.EventCleanerTask,org.apache.hadoop.hive.metastore.MaterializationsCacheCleanerTask</value>
      </property>
      <property>
        <name>metastore.expression.proxy</name>
        <value>org.apache.hadoop.hive.metastore.DefaultPartitionExpressionProxy</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.postgresql.Driver</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:postgresql://{{ .Release.Name }}-pg-metastore-svc:5432/metadata</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>password</value>
      </property>
      <property>
        <name>hive.metastore.uris</name>
        <value>thrift://localhost:9083</value>
      </property>
      <property>
        <name>metastore.thrift.port</name>
        <value>9083</value>
      </property>
    </configuration>
  metastore-log4j2.properties: |
    # Licensed to the Apache Software Foundation (ASF) under one
    # or more contributor license agreements.  See the NOTICE file
    # distributed with this work for additional information
    # regarding copyright ownership.  The ASF licenses this file
    # to you under the Apache License, Version 2.0 (the
    # "License"); you may not use this file except in compliance
    # with the License.  You may obtain a copy of the License at
    #
    #     http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.

    status = INFO
    name = MetastoreLog4j2
    packages = org.apache.hadoop.hive.metastore

    # list of properties
    property.metastore.log.level = INFO
    property.metastore.root.logger = DRFA
    property.metastore.log.dir = ${sys:java.io.tmpdir}/${sys:user.name}
    property.metastore.log.file = metastore.log
    property.hive.perflogger.log.level = INFO

    # list of all appenders
    appenders = console, DRFA

    # console appender
    appender.console.type = Console
    appender.console.name = console
    appender.console.target = SYSTEM_ERR
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{ISO8601} %5p [%t] %c{2}: %m%n

    # daily rolling file appender
    appender.DRFA.type = RollingRandomAccessFile
    appender.DRFA.name = DRFA
    appender.DRFA.fileName = ${sys:metastore.log.dir}/${sys:metastore.log.file}
    # Use %pid in the filePattern to append <process-id>@<host-name> to the filename if you want separate log files for different CLI session
    appender.DRFA.filePattern = ${sys:metastore.log.dir}/${sys:metastore.log.file}.%d{yyyy-MM-dd}
    appender.DRFA.layout.type = PatternLayout
    appender.DRFA.layout.pattern = %d{ISO8601} %5p [%t] %c{2}: %m%n
    appender.DRFA.policies.type = Policies
    appender.DRFA.policies.time.type = TimeBasedTriggeringPolicy
    appender.DRFA.policies.time.interval = 1
    appender.DRFA.policies.time.modulate = true
    appender.DRFA.strategy.type = DefaultRolloverStrategy
    appender.DRFA.strategy.max = 30

    # list of all loggers
    loggers = DataNucleus, Datastore, JPOX, PerfLogger

    logger.DataNucleus.name = DataNucleus
    logger.DataNucleus.level = ERROR

    logger.Datastore.name = Datastore
    logger.Datastore.level = ERROR

    logger.JPOX.name = JPOX
    logger.JPOX.level = ERROR

    logger.PerfLogger.name = org.apache.hadoop.hive.ql.log.PerfLogger
    logger.PerfLogger.level = ${sys:hive.perflogger.log.level}

    # root logger
    rootLogger.level = ${sys:metastore.log.level}
    rootLogger.appenderRefs = root
    rootLogger.appenderRef.root.ref = ${sys:metastore.root.logger}
{{ end}}
{{- else }}
data:
  core-site.xml: |
      {{ .Values.s3.coreSite.xmlContent}}
  metastore-site.xml: |
      <configuration>
        <property>
          <name>metastore.task.threads.always</name>
          <value>org.apache.hadoop.hive.metastore.events.EventCleanerTask,org.apache.hadoop.hive.metastore.MaterializationsCacheCleanerTask</value>
        </property>
        <property>
          <name>metastore.expression.proxy</name>
          <value>org.apache.hadoop.hive.metastore.DefaultPartitionExpressionProxy</value>
        </property>
        <property>
          <name>javax.jdo.option.ConnectionDriverName</name>
          <value>org.postgresql.Driver</value>
        </property>
        <property>
          <name>javax.jdo.option.ConnectionURL</name>
          <value>jdbc:postgresql://{{ .Release.Name }}-pg-metastore-svc:5432/metadata</value>
        </property>
        <property>
          <name>javax.jdo.option.ConnectionUserName</name>
          <value>hive</value>
        </property>
        <property>
          <name>javax.jdo.option.ConnectionPassword</name>
          <value>password</value>
        </property>
        <property>
          <name>hive.metastore.uris</name>
          <value>thrift://localhost:9083</value>
        </property>
        <property>
          <name>metastore.thrift.port</name>
          <value>9083</value>
        </property>
      </configuration>
  metastore-log4j2.properties: |
    # Licensed to the Apache Software Foundation (ASF) under one
    # or more contributor license agreements.  See the NOTICE file
    # distributed with this work for additional information
    # regarding copyright ownership.  The ASF licenses this file
    # to you under the Apache License, Version 2.0 (the
    # "License"); you may not use this file except in compliance
    # with the License.  You may obtain a copy of the License at
    #
    #     http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.

    status = INFO
    name = MetastoreLog4j2
    packages = org.apache.hadoop.hive.metastore

    # list of properties
    property.metastore.log.level = INFO
    property.metastore.root.logger = DRFA
    property.metastore.log.dir = ${sys:java.io.tmpdir}/${sys:user.name}
    property.metastore.log.file = metastore.log
    property.hive.perflogger.log.level = INFO

    # list of all appenders
    appenders = console, DRFA

    # console appender
    appender.console.type = Console
    appender.console.name = console
    appender.console.target = SYSTEM_ERR
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{ISO8601} %5p [%t] %c{2}: %m%n

    # daily rolling file appender
    appender.DRFA.type = RollingRandomAccessFile
    appender.DRFA.name = DRFA
    appender.DRFA.fileName = ${sys:metastore.log.dir}/${sys:metastore.log.file}
    # Use %pid in the filePattern to append <process-id>@<host-name> to the filename if you want separate log files for different CLI session
    appender.DRFA.filePattern = ${sys:metastore.log.dir}/${sys:metastore.log.file}.%d{yyyy-MM-dd}
    appender.DRFA.layout.type = PatternLayout
    appender.DRFA.layout.pattern = %d{ISO8601} %5p [%t] %c{2}: %m%n
    appender.DRFA.policies.type = Policies
    appender.DRFA.policies.time.type = TimeBasedTriggeringPolicy
    appender.DRFA.policies.time.interval = 1
    appender.DRFA.policies.time.modulate = true
    appender.DRFA.strategy.type = DefaultRolloverStrategy
    appender.DRFA.strategy.max = 30

    # list of all loggers
    loggers = DataNucleus, Datastore, JPOX, PerfLogger

    logger.DataNucleus.name = DataNucleus
    logger.DataNucleus.level = ERROR

    logger.Datastore.name = Datastore
    logger.Datastore.level = ERROR

    logger.JPOX.name = JPOX
    logger.JPOX.level = ERROR

    logger.PerfLogger.name = org.apache.hadoop.hive.ql.log.PerfLogger
    logger.PerfLogger.level = ${sys:hive.perflogger.log.level}

    # root logger
    rootLogger.level = ${sys:metastore.log.level}
    rootLogger.appenderRefs = root
    rootLogger.appenderRef.root.ref = ${sys:metastore.root.logger}
{{ end}}
